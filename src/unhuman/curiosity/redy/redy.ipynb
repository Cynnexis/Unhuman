{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "redy.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hhzWBYDVrPHH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KaGH0cA-r8Bh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Unhuman Project #"
      ]
    },
    {
      "metadata": {
        "id": "xoRMLX46sF3V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Curiosity - Redy ##"
      ]
    },
    {
      "metadata": {
        "id": "NefDhQ2xsLdH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is about the neural network that can recognize red from an RGB value."
      ]
    },
    {
      "metadata": {
        "id": "kkSf6WYesW9D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Getting Started ###"
      ]
    },
    {
      "metadata": {
        "id": "e9wVB0HWvsrH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we must import the necessary modules:"
      ]
    },
    {
      "metadata": {
        "id": "IslJb33mr4Ju",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "print(\"TensorFlow version: {0}\\nKeras version: {1}\".format(tf.__version__, keras.__version__))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8LHak1Tscn1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then we must create the model. It is a Sequential containing 3 dense neuron layers:"
      ]
    },
    {
      "metadata": {
        "id": "RxwFH5q8sI_A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(3,), dtype=tf.float32),\n",
        "\tkeras.layers.Dense(units=16, activation=\"relu\", kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
        "\tkeras.layers.Dense(units=16, activation=\"relu\", kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
        "\tkeras.layers.Dense(units=16, activation=\"relu\", kernel_initializer='glorot_uniform', bias_initializer='zeros'),\n",
        "\tkeras.layers.Dense(units=1, activation=\"sigmoid\", kernel_initializer='glorot_uniform', bias_initializer='zeros')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQscvm9jwAx5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training ###"
      ]
    },
    {
      "metadata": {
        "id": "BDN1TkQbwUeV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then, we create a very simple dataset for the training. First of all, we must access Google Drive file to fetch the CSV training file (see [this notebook for more detail about Google Drive integration with Colab Research](https://colab.research.google.com/notebooks/io.ipynb)):"
      ]
    },
    {
      "metadata": {
        "id": "WtKCRHUXwXcc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import_file_anyway = False #@param {type:\"boolean\"}\n",
        "default_training_filename = \"training_dataset (11).csv\" #@param {type: \"string\"}\n",
        "\n",
        "training_filename = default_training_filename\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "from google.colab import files\n",
        "\n",
        "raw_content = \"\"\n",
        "\n",
        "if not os.path.isfile(training_filename) or import_file_anyway:\n",
        "    uploaded = {}\n",
        "    \n",
        "    while len(uploaded) <= 0:\n",
        "        uploaded = files.upload()\n",
        "        print(uploaded)\n",
        "    \n",
        "    training_filename = next(iter(uploaded))\n",
        "    raw_content = uploaded[training_filename].decode('utf-8')\n",
        "else:\n",
        "    with open(training_filename, 'r') as f:\n",
        "        raw_content = f.read()\n",
        "    \n",
        "print(\"Successfully uploaded '{}'.\".format(training_filename))\n",
        "\n",
        "del import_file_anyway\n",
        "del default_training_filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vhek5Ms52Hnq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's import the dataset and put them in the lists ```features```,  ```labels``` and  ```dataset```(which contains tuples of feature and label):\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1AQ30NBUpZVk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "csv_format = pd.read_csv(io.StringIO(raw_content), skiprows=1)\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "dataset = []\n",
        "\n",
        "def convert_color(color):\n",
        "    if isinstance(color, list):\n",
        "        if (len(color) == 1 and isinstance(color[0], list)):\n",
        "            return [[color[0][0] / 255, color[0][1] / 255, color[0][2] / 255]]\n",
        "    else:\n",
        "        return [color[0] / 255, color[1] / 255, color[2] / 255]\n",
        "\n",
        "for index, row in csv_format.iterrows():\n",
        "    # Change basis [0 ; 255] to [0 ; 1] for features\n",
        "    features.append(convert_color(row))\n",
        "    labels.append(row[3])\n",
        "    dataset.append((features[-1], labels[-1]))\n",
        "\n",
        "del csv_format\n",
        "\n",
        "# Print dataset in a human way\n",
        "print(\"Number of training entr{1}: {0}\".format(len(dataset), 'y' if len(dataset) <= 1 else \"ies\"))\n",
        "i = 0\n",
        "for x, y in dataset:\n",
        "    print(\"[{0:.2f}, {1:.2f}, {2:.2f}] -> {3}  ({4})\".format(x[0], x[1], x[2], y, \"Red-ish\" if y > 0.5 else \"Not red\"))\n",
        "    i += 1\n",
        "    if (i >= 15):\n",
        "        print(\"... [{} more]\".format(len(dataset) - i))\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CcuHkLvVwZ9R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, make the training loop:"
      ]
    },
    {
      "metadata": {
        "id": "JaDIk2p1sfmx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "learning_rate = 1. #@param {type: \"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.train.GradientDescentOptimizer(learning_rate), #GradientDescentOptimizer tf.train.AdadeltaOptimizer\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "np_features = np.array(features, dtype=np.float32)\n",
        "np_labels = np.array(labels, dtype=np.float32)\n",
        "\n",
        "#print(\"np_features = ({} containing {} elem) {}\\nnp_labels = ({} containing {} elem) {}\".format(type(np_features), len(np_features), np_features, type(np_labels), len(np_labels), np_labels))\n",
        "\n",
        "model.fit(\n",
        "    x=np_features,\n",
        "    y=np_labels,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    validation_data=(np_features, np_labels)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kqn5-LOL2XFO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tests ###"
      ]
    },
    {
      "metadata": {
        "id": "aZfqFv5U5UbZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "result = model.evaluate(np_features, np_labels, batch_size=32)\n",
        "\n",
        "print(\"loss = {0}\\naccuracy = {1:.3%}\".format(result[0], result[1]))\n",
        "\n",
        "del result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7dm1JEV_2bGu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predictions ###"
      ]
    },
    {
      "metadata": {
        "id": "F8iuf3C52c-7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, let's make some predictions:"
      ]
    },
    {
      "metadata": {
        "id": "gHqUbbzf3Ncj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Make some prediction by typing a color: { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "red   = 243 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "green = 10 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "blue  = 6 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "\n",
        "color = [red, green, blue]\n",
        "np_color = np.array(convert_color([color]), dtype=np.float32)\n",
        "\n",
        "# Display the color with matplotlib\n",
        "try:\n",
        "    fig, ax = plt.subplots(1)\n",
        "    rect = matplotlib.patches.Rectangle((0, 0), 1, 1, fill=True, color=(red / 255, green / 255, blue / 255))\n",
        "    ax.add_patch(rect)\n",
        "    ax.grid(False)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    del fig\n",
        "    del ax\n",
        "    del rect\n",
        "except:\n",
        "    pass\n",
        "\n",
        "result = model.predict(np_color)[0][0]\n",
        "confidence = result if result >= 0.5 else 1. - result\n",
        "print(\"Accuracy: {0:.3%}\\nThe color is \\x1b[1;31m{1}red\\x1b[0m ; the program is confident at {2:.2%}\".format(result, \"\" if result > 0.5 else \"not \", confidence))\n",
        "\n",
        "del result\n",
        "del confidence"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}